import requests
import datetime
import logging
import threading
import time
import sqlite3
import json
from concurrent.futures import ThreadPoolExecutor, as_completed
from app.core.config import cfg
from app.core.database import DB_PATH

logger = logging.getLogger("uvicorn")

class CalendarService:
    def __init__(self):
        # ç¼“å­˜ç»“æ„: { offset: {'data': ..., 'time': timestamp} }
        self._cache = {} 
        self._cache_lock = threading.Lock()
        
        # ğŸ”¥ å¯åŠ¨åå°å®šæ—¶åŒæ­¥ä»»åŠ¡
        self._start_background_sync()

    def _start_background_sync(self):
        """åå°ç‹¬ç«‹çº¿ç¨‹ï¼šå®šæ—¶æ‹‰å– TMDB æ’æœŸå¹¶è½ç›˜ï¼Œé˜²æ­¢ç”¨æˆ·é¦–æ¬¡æ‰“å¼€åŠ è½½è¿‡æ…¢"""
        def sync_task():
            # å»¶è¿Ÿ 60 ç§’å¯åŠ¨ï¼Œç­‰ FastAPI ä¸»æœåŠ¡å’Œæ•°æ®åº“éƒ½å½»åº•è·‘èµ·æ¥
            time.sleep(60)
            while True:
                try:
                    logger.info("ğŸ”„ [å®šæ—¶ä»»åŠ¡] å¼€å§‹åœ¨åå°è‡ªåŠ¨æ‹‰å–å¹¶æ›´æ–°è¿½å‰§æ—¥å†...")
                    # å¼ºåˆ¶åˆ·æ–°æœ¬å‘¨ (offset=0) å’Œ ä¸‹å‘¨ (offset=1) çš„æ•°æ®å†™å…¥æœ¬åœ° DB
                    self.get_weekly_calendar(force_refresh=True, week_offset=0)
                    self.get_weekly_calendar(force_refresh=True, week_offset=1)
                    logger.info("âœ… [å®šæ—¶ä»»åŠ¡] è¿½å‰§æ—¥å†æ›´æ–°å®Œæ¯•ï¼Œæ•°æ®å·²è½ç›˜ã€‚")
                except Exception as e:
                    logger.error(f"åå°æ›´æ–°æ—¥å†å¤±è´¥: {e}")
                
                # ä¼‘çœ  12 å°æ—¶ (43200ç§’) åå†æ¬¡æ‰§è¡Œ
                time.sleep(43200)
        
        # è®¾ç½® daemon=Trueï¼Œè¿™æ ·ä¸»è¿›ç¨‹ç»“æŸæ—¶ï¼Œè¿™ä¸ªçº¿ç¨‹ä¹Ÿä¼šè‡ªåŠ¨é”€æ¯
        t = threading.Thread(target=sync_task, daemon=True)
        t.start()

    def _get_proxies(self):
        """è·å–å…¨å±€ä»£ç†é…ç½®"""
        proxy = cfg.get("proxy_url")
        if proxy:
            return {"http": proxy, "https": proxy}
        return None

    def mark_episode_ready(self, series_id, season, episode):
        """Webhook ä¸“ç”¨ï¼šæ–°é›†å…¥åº“æ—¶ï¼Œå°†æœ¬åœ°ç¼“å­˜çŠ¶æ€ç‚¹äº®ä¸ºå·²å…¥åº“ (ready)"""
        try:
            conn = sqlite3.connect(DB_PATH)
            c = conn.cursor()
            c.execute('''UPDATE tv_calendar_cache 
                         SET status = 'ready' 
                         WHERE series_id = ? AND season = ? AND episode = ?''', 
                      (series_id, season, episode))
            conn.commit()
            conn.close()
            # æ¸…ç†å†…å­˜ç¼“å­˜ï¼Œç¡®ä¿ä¸‹æ¬¡åˆ·æ–°é¡µé¢æ—¶è¯»åˆ°æœ€æ–°ç»¿ç¯
            with self._cache_lock:
                self._cache.clear()
            logger.info(f"ğŸŸ¢ [æ—¥å†è”åŠ¨] å‰§é›†å…¥åº“ï¼Œçº¢ç¯å˜ç»¿ç¯: SeriesId={series_id} S{season}E{episode}")
        except Exception as e:
            logger.error(f"æ—¥å†çŠ¶æ€æ›´æ–°å¤±è´¥: {e}")

    def get_weekly_calendar(self, force_refresh=False, week_offset=0):
        """
        è·å–å‘¨å†
        """
        now = time.time()
        
        # åŠ¨æ€è·å–é…ç½®ï¼Œé»˜è®¤ 1 å¤© (86400ç§’)
        cache_ttl = int(cfg.get("calendar_cache_ttl") or 86400)

        # 1. æ£€æŸ¥å¯¹åº”å‘¨çš„å†…å­˜ç¼“å­˜ (å¦‚æœæ˜¯å‰ç«¯æ™®é€šè¯·æ±‚ï¼Œä¸”æ²¡è¿‡æœŸ)
        if not force_refresh:
            with self._cache_lock:
                cached_item = self._cache.get(week_offset)
                if cached_item and (now - cached_item['time'] < cache_ttl):
                    return cached_item['data']

        api_key = cfg.get("tmdb_api_key")
        if not api_key:
            return {"error": "æœªé…ç½® TMDB API Key"}

        # 2. è®¡ç®—ç›®æ ‡å‘¨çš„æ—¶é—´èŒƒå›´
        target_date = datetime.date.today() + datetime.timedelta(weeks=week_offset)
        start_of_week = target_date - datetime.timedelta(days=target_date.weekday())
        end_of_week = start_of_week + datetime.timedelta(days=6)
        
        # 3. ä» Emby è·å–æ‰€æœ‰â€œè¿è½½ä¸­â€çš„å‰§é›†
        continuing_series = self._get_emby_continuing_series()
        if not continuing_series:
            return {"days": []}

        # 4. ä¼˜åŒ–ï¼šå…ˆå°è¯•ä»æœ¬åœ° SQLite è·å–è¿™ä¸€å‘¨çš„æ•°æ®
        week_data = {i: [] for i in range(7)}
        start_date_str = start_of_week.strftime("%Y-%m-%d")
        end_date_str = end_of_week.strftime("%Y-%m-%d")
        
        has_db_data = False
        try:
            conn = sqlite3.connect(DB_PATH)
            c = conn.cursor()
            c.execute("SELECT status, data_json FROM tv_calendar_cache WHERE air_date >= ? AND air_date <= ?", (start_date_str, end_date_str))
            rows = c.fetchall()
            if rows and not force_refresh:
                has_db_data = True
                for row in rows:
                    db_status = row[0]
                    data_dict = json.loads(row[1])
                    data_dict["status"] = db_status # ğŸ”¥ å…³é”®ï¼šç”¨ Webhook æ›´æ–°åçš„æœ€æ–°çŠ¶æ€è¦†ç›–
                    
                    try:
                        air_date_obj = datetime.datetime.strptime(data_dict["air_date"], "%Y-%m-%d").date()
                        day_index = (air_date_obj - start_of_week).days
                        if 0 <= day_index <= 6:
                            week_data[day_index].append(data_dict)
                    except: pass
            conn.close()
        except Exception as e:
            logger.error(f"DB Read Error: {e}")

        # 5. å¦‚æœæœ¬åœ°æ²¡æ•°æ®æˆ–å¼ºåˆ¶åˆ·æ–°ï¼Œæ‰å»å¹¶å‘æŸ¥ TMDB å’Œ Emby
        if not has_db_data or force_refresh:
            # æ¸…ç©ºåˆšæ‰å¯èƒ½åŠ è½½çš„ä¸å®Œæ•´æœ¬åœ°æ•°æ®
            week_data = {i: [] for i in range(7)}
            proxies = self._get_proxies()
            
            with ThreadPoolExecutor(max_workers=20) as executor:
                future_to_series = {
                    executor.submit(self._fetch_series_status, s, api_key, start_of_week, end_of_week, proxies): s 
                    for s in continuing_series
                }
                
                for future in as_completed(future_to_series):
                    try:
                        results = future.result()
                        if results:
                            for item in results:
                                idx = item['day_index']
                                if 0 <= idx <= 6:
                                    week_data[idx].append(item['data'])
                    except Exception as e:
                        logger.error(f"Calendar Task Error: {e}")
            
            # ğŸ”¥ æ–°å¢ï¼šå°†æŸ¥å›æ¥çš„å…¨æ–°æ•°æ®è½ç›˜åˆ°æœ¬åœ°æ•°æ®åº“
            try:
                conn = sqlite3.connect(DB_PATH)
                c = conn.cursor()
                for i in range(7):
                    for data_dict in week_data[i]:
                        series_id = data_dict.get("series_id")
                        season = data_dict.get("season")
                        episode = data_dict.get("episode")
                        air_date = data_dict.get("air_date")
                        status = data_dict.get("status")
                        
                        if series_id and season is not None and episode is not None:
                            id_key = f"{series_id}_{season}_{episode}"
                            c.execute('''INSERT OR REPLACE INTO tv_calendar_cache 
                                         (id, series_id, season, episode, air_date, status, data_json) 
                                         VALUES (?, ?, ?, ?, ?, ?, ?)''', 
                                      (id_key, series_id, season, episode, air_date, status, json.dumps(data_dict)))
                conn.commit()
                conn.close()
            except Exception as e:
                logger.error(f"DB Write Error: {e}")

        # 6. æ™ºèƒ½åˆå¹¶ä¸å»é‡
        for i in range(7):
            raw_items = week_data[i]
            if not raw_items: continue

            grouped = {}
            for item in raw_items:
                key = (item.get('tmdb_id') or item['series_id'], item['season'])
                if key not in grouped:
                    grouped[key] = []
                grouped[key].append(item)
            
            merged_items = []
            for key, group in grouped.items():
                unique_eps = {}
                for x in group:
                    unique_eps[x['episode']] = x
                
                sorted_eps = sorted(unique_eps.values(), key=lambda x: x['episode'])
                if not sorted_eps: continue

                if len(sorted_eps) == 1:
                    merged_items.append(sorted_eps[0])
                else:
                    first = sorted_eps[0]
                    last = sorted_eps[-1]
                    merged = first.copy()
                    merged['episode'] = f"{first['episode']}-{last['episode']}"
                    merged['ep_name'] = None 
                    statuses = [x['status'] for x in sorted_eps]
                    if 'missing' in statuses:
                        merged['status'] = 'missing'
                    elif 'ready' in statuses:
                        merged['status'] = 'ready'
                    else:
                        merged['status'] = 'upcoming'
                    merged_items.append(merged)
            
            week_data[i] = merged_items

        # 7. æ’åºä¸æ ¼å¼åŒ–
        final_days = []
        week_dates = [start_of_week + datetime.timedelta(days=i) for i in range(7)]
        today_real = datetime.date.today()
        
        for i in range(7):
            items = sorted(week_data[i], key=lambda x: x['air_date'])
            final_days.append({
                "date": week_dates[i].strftime("%Y-%m-%d"),
                "weekday_cn": ["å‘¨ä¸€", "å‘¨äºŒ", "å‘¨ä¸‰", "å‘¨å››", "å‘¨äº”", "å‘¨å…­", "å‘¨æ—¥"][i],
                "is_today": week_dates[i] == today_real, 
                "items": items
            })
        
        # è·å–å…¬ç½‘/å†…ç½‘åœ°å€
        emby_url = cfg.get("emby_public_url") or cfg.get("emby_public_host") or cfg.get("emby_host") or ""
        if emby_url.endswith('/'): emby_url = emby_url[:-1]

        # ğŸ”¥ è·å– Emby ServerId (è§£å†³è·³è½¬æ’­æ”¾éªŒè¯é—®é¢˜)
        server_id = ""
        try:
            key = cfg.get("emby_api_key"); host = cfg.get("emby_host")
            sys_res = requests.get(f"{host}/emby/System/Info?api_key={key}", timeout=5)
            if sys_res.status_code == 200:
                server_id = sys_res.json().get("Id", "")
        except: pass

        result = {
            "days": final_days, 
            "updated_at": datetime.datetime.now().strftime("%H:%M"),
            "emby_url": emby_url,
            "server_id": server_id, # ğŸ”¥ è¿”å› ServerId
            "date_range": f"{start_of_week.strftime('%m/%d')} - {end_of_week.strftime('%m/%d')}",
            "current_ttl": cache_ttl 
        }
        
        with self._cache_lock:
            self._cache[week_offset] = {
                'data': result,
                'time': now
            }
            
        return result

    def _get_emby_continuing_series(self):
        key = cfg.get("emby_api_key"); host = cfg.get("emby_host")
        user_id = self._get_admin_id()
        if not key or not host or not user_id: return []

        url = f"{host}/emby/Users/{user_id}/Items"
        params = {
            "IncludeItemTypes": "Series",
            "Recursive": "true",
            "Fields": "ProviderIds,Status,AirDays",
            "IsVirtual": "false",
            "api_key": key
        }
        try:
            res = requests.get(url, params=params, timeout=10)
            if res.status_code == 200:
                items = res.json().get("Items", [])
                return [i for i in items if i.get("Status") == "Continuing" and i.get("ProviderIds", {}).get("Tmdb")]
        except Exception as e:
            logger.error(f"Emby Series Fetch Error: {e}")
            return []
        return []

    def _fetch_series_status(self, series, api_key, start_date, end_date, proxies):
        """æŸ¥è¯¢ TMDB å¹¶æ¯”å¯¹æœ¬åœ°åº“å­˜"""
        tmdb_id = series.get("ProviderIds", {}).get("Tmdb")
        if not tmdb_id: return []

        try:
            url_series = f"https://api.themoviedb.org/3/tv/{tmdb_id}?api_key={api_key}&language=zh-CN"
            res_series = requests.get(url_series, timeout=5, proxies=proxies)
            if res_series.status_code != 200: return []
            
            data_series = res_series.json()
            target_seasons = set()
            
            if data_series.get("last_episode_to_air"):
                target_seasons.add(data_series["last_episode_to_air"].get("season_number"))
            if data_series.get("next_episode_to_air"):
                target_seasons.add(data_series["next_episode_to_air"].get("season_number"))
            
            if not target_seasons and data_series.get("seasons"):
                last_season = data_series["seasons"][-1]
                target_seasons.add(last_season.get("season_number"))

            final_episodes = []

            for season_num in target_seasons:
                if season_num is None: continue
                
                url_season = f"https://api.themoviedb.org/3/tv/{tmdb_id}/season/{season_num}?api_key={api_key}&language=zh-CN"
                res_season = requests.get(url_season, timeout=5, proxies=proxies)
                if res_season.status_code != 200: continue
                
                episodes_list = res_season.json().get("episodes", [])
                
                for ep in episodes_list:
                    air_date_str = ep.get("air_date")
                    if not air_date_str: continue
                    
                    try:
                        air_date = datetime.datetime.strptime(air_date_str, "%Y-%m-%d").date()
                    except: continue

                    if start_date <= air_date <= end_date:
                        season_val = ep.get("season_number")
                        ep_val = ep.get("episode_number")
                        
                        has_file = self._check_emby_has_episode(series["Id"], season_val, ep_val)
                        
                        status = "upcoming"
                        today = datetime.date.today()
                        
                        if has_file:
                            status = "ready"
                        elif air_date < today:
                            status = "missing"
                        elif air_date == today:
                            status = "today" 

                        final_episodes.append({
                            "day_index": (air_date - start_date).days,
                            "data": {
                                "series_name": series.get("Name"),
                                "series_id": series.get("Id"),
                                "tmdb_id": tmdb_id,
                                "ep_name": ep.get("name"),
                                "season": season_val,
                                "episode": ep_val,
                                "air_date": ep.get("air_date"),
                                "poster_path": data_series.get("poster_path"),
                                "status": status,
                                "overview": ep.get("overview")
                            }
                        })
            
            return final_episodes
        except Exception as e:
            return []

    def _check_emby_has_episode(self, series_id, season, episode):
        key = cfg.get("emby_api_key"); host = cfg.get("emby_host")
        user_id = self._get_admin_id()
        if not key or not host or not user_id: return False
        
        url = f"{host}/emby/Users/{user_id}/Items"
        params = {
            "ParentId": series_id,
            "Recursive": "true",
            "IncludeItemTypes": "Episode",
            "ParentIndexNumber": season,
            "IndexNumber": episode,
            "IsVirtual": "false",        # ğŸ”¥ æ ¸å¿ƒä¿®å¤ 1ï¼šç›´æ¥åœ¨ API å±‚é¢æ‹’æ”¶è™šæ‹Ÿå ä½ç¬¦
            "Limit": 1,
            "Fields": "Id,LocationType", # ğŸ”¥ è¯·æ±‚è¿”å› LocationType å­—æ®µ
            "api_key": key
        }
        try:
            res = requests.get(url, params=params, timeout=2)
            if res.status_code == 200:
                items = res.json().get("Items", [])
                if items:
                    # ğŸ”¥ æ ¸å¿ƒä¿®å¤ 2ï¼šåŒé‡ä¿é™©ï¼Œç¡®ä¿å®ƒæ˜¯ä¸€ä¸ªçœŸå®çš„ç‰©ç†æ–‡ä»¶è€Œä¸æ˜¯åˆ®å‰Šçš„ç©ºå£³
                    return items[0].get("LocationType", "") != "Virtual"
        except: pass
        return False

    def _get_admin_id(self):
        key = cfg.get("emby_api_key"); host = cfg.get("emby_host")
        try:
            res = requests.get(f"{host}/emby/Users?api_key={key}", timeout=3)
            if res.status_code == 200:
                users = res.json()
                for u in users:
                    if u.get("Policy", {}).get("IsAdministrator"):
                        return u['Id']
                return users[0]['Id']
        except: pass
        return None

calendar_service = CalendarService()